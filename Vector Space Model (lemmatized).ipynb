{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from nltk.stem.porter import *\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5.QtWidgets import QApplication,QMainWindow\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import operator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "- removing stop words from document\n",
    "- lemmatizing words in document\n",
    "- Making dictionary of all terms in document \n",
    "- creating term frequency matrix\n",
    "- creating tf-idf matrix\n",
    "- finding magnitudes of document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if lemmatizer is not working\n",
    "- steps\n",
    "- import nltk\n",
    "- nltk.download()\n",
    "- from collections\n",
    "- from all packages tab wordnet\n",
    "- run the below cell to follow the steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "document_matrix = {}\n",
    "\n",
    "def create_stoplist(): #creating stopword list \n",
    "    stop_list_f = open(\"Stopword-list.txt\",\"r\")\n",
    "    stop_list = stop_list_f.read()\n",
    "    stop_list.replace(\" \",\"\")\n",
    "    stopword_list = stop_list.split(\"\\n\")\n",
    "    return stopword_list\n",
    "\n",
    "def create_wordlist(docID): #creating list of all words document\n",
    "    f = open(str(docID)+\".txt\", \"r\",encoding=\"utf-8\")\n",
    "    f_read=f.read()\n",
    "#     print(f_read)\n",
    "    f_read=f_read.lower() #lower case complete document \n",
    "    f_read = f_read.replace(\"\\n\",\" \") #removing new line character\n",
    "    f_read = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,“”’———‘*1234567890]\",\"\", f_read) #removing punctuations\n",
    "    f_list = f_read.split(\" \") \n",
    "    f_list=[x for x in f_list if x] #creating list of words\n",
    "    words = [x for x in f_list if x not in stopword_list] #removing stopwords from the list of words\n",
    "    words = [lemmatizer.lemmatize(x) for x in words]\n",
    "    return words\n",
    "\n",
    "\n",
    "def create_term_frequency(words,docID): ## creating term frequency matrix {word: [documentFrequency,{docID: termFrequency}]}\n",
    "#     print(words)\n",
    "    for pos,term in enumerate(words):\n",
    "#         print(words[word])\n",
    "        if term not in term_frequency:\n",
    "            term_frequency[term] = []\n",
    "            term_frequency[term].append(1)\n",
    "            term_frequency[term].append({})\n",
    "            term_frequency[term][1][docID] = 1\n",
    "        else:\n",
    "#             print(term_frequency)\n",
    "            if docID in term_frequency[term][1]:\n",
    "                term_frequency[term][1][docID] = term_frequency[term][1][docID] + 1\n",
    "            else:\n",
    "                term_frequency[term][1][docID] = 1\n",
    "                term_frequency[term][0] = term_frequency[term][0] + 1\n",
    "    \n",
    "    sorted_index = sorted(term_frequency.items(), key = lambda kv: kv[0])\n",
    "    sorted_index = dict(sorted_index)\n",
    "    return sorted_index\n",
    "\n",
    "\n",
    "def create_matrix(words,words_dictionary,docID):\n",
    "    for i in range(0,len(words_dictionary)):\n",
    "        if docID not in document_matrix:\n",
    "            document_matrix[docID] = []\n",
    "        document_matrix[docID].append(0)\n",
    "    for i in range(0,len(words)):\n",
    "        index = words_dictionary.index(words[i])\n",
    "        document_matrix[docID][index] = 1\n",
    "        \n",
    "    return document_matrix\n",
    "\n",
    "\n",
    "def create_idf_matrix(words_dictionary,term_frequency): ## calculating tf-idf of all terms in every document\n",
    "    idf_values = {}\n",
    "    total_documents = 50.00\n",
    "    for i in range(0,len(words_dictionary)):\n",
    "        temp = math.log10(term_frequency[words_dictionary[i]][0])/total_documents\n",
    "        idf_values[words_dictionary[i]] = temp\n",
    "    return idf_values\n",
    "\n",
    "\n",
    "def create_tf_idf_matrix(words,words_dictionary,docID,idf_values,term_frequency): ##creating tf-idf matrix of terms in document\n",
    "#     for i in range(0,len(words_dictionary)):\n",
    "    if docID not in document_matrix:\n",
    "        document_matrix[docID] = []\n",
    "    document_matrix[docID] = [0] * len(words_dictionary)\n",
    "    for i in range(0,len(words)):\n",
    "        index = words_dictionary.index(words[i])\n",
    "        temp = idf_values[words[i]] * term_frequency[words[i]][1][docID]\n",
    "        document_matrix[docID][index] = temp\n",
    "    return document_matrix\n",
    "\n",
    "\n",
    "def find_magnitudes_of_documents(tf_idf_matrix): ##finding magnitudes of all documents using tf-idf matrix\n",
    "    magnitude = {}\n",
    "    for i in range(1,51):\n",
    "#         print(i)\n",
    "        squared_numbers = [number ** 2 for number in tf_idf_matrix[i]]\n",
    "#         print(squared_numbers)\n",
    "        total = sum(squared_numbers)\n",
    "#         print(total)\n",
    "        magnitude[i] = math.sqrt(total)\n",
    "#         print(magnitude[i])\n",
    "    return magnitude\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015563025007672872\n"
     ]
    }
   ],
   "source": [
    "words_dictionary = []\n",
    "stopword_list = []\n",
    "words = []\n",
    "stopword_list = create_stoplist()\n",
    "term_frequency = {}\n",
    "tf_idf_matrix = {}\n",
    "\n",
    "document_frequency = {}\n",
    "\n",
    "for docID in range (1,51):\n",
    "    words = create_wordlist(docID)\n",
    "    words.sort()\n",
    "    term_frequency = create_term_frequency(words,docID)\n",
    "\n",
    "words_dictionary = list(term_frequency.keys()) ##creating list of all terms in document\n",
    "\n",
    "idf_values = create_idf_matrix(words_dictionary,term_frequency)\n",
    "print(idf_values['due'])\n",
    "\n",
    "\n",
    "for docID in range (1,51):\n",
    "    tf_idf_matrix = {}\n",
    "    words = create_wordlist(docID)\n",
    "    words.sort()\n",
    "    tf_idf_matrix = create_tf_idf_matrix(words,words_dictionary,docID,idf_values,term_frequency)\n",
    "    \n",
    "    \n",
    "term_frequency_file = open(\"term_frequency.json\", \"w\")\n",
    "json.dump(term_frequency, term_frequency_file, indent = 6)\n",
    "term_frequency_file.close()     \n",
    "tf_idf_matrix_file = open(\"tf_idf_matrix.json\", \"w\")\n",
    "json.dump(tf_idf_matrix, tf_idf_matrix_file, indent = 6)\n",
    "tf_idf_matrix_file.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitudes = {}\n",
    "magnitudes = find_magnitudes_of_documents(tf_idf_matrix)\n",
    "# print(magnitudes)\n",
    "magnitudes_file = open(\"magnitudes.json\", \"w\")\n",
    "json.dump(magnitudes, magnitudes_file, indent = 6)\n",
    "magnitudes_file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency_file = open('term_frequency.json',)\n",
    "term_frequency = json.load(term_frequency_file)\n",
    "tf_idf_matrix_file = open('tf_idf_matrix.json',)\n",
    "tf_idf_matrix = json.load(tf_idf_matrix_file)\n",
    "magnitudes_file = open('magnitudes.json',)\n",
    "magnitudes = json.load(magnitudes_file)\n",
    "\n",
    "\n",
    "\n",
    "def q_term_frequency(new_query): #calculating ter frequency of query\n",
    "    query_term_frequency = {}\n",
    "    for pos,term in enumerate(new_query):\n",
    "        if term not in query_term_frequency:\n",
    "            query_term_frequency[term] = 1\n",
    "        else:\n",
    "            query_term_frequency[term] = query_term_frequency[term] + 1\n",
    "    query_sorted_index = sorted(query_term_frequency.items(), key = lambda kv: kv[0])\n",
    "    query_sorted_index = dict(query_sorted_index)\n",
    "    return query_sorted_index\n",
    "\n",
    "def create_q_tf_idf_matrix(query_term_frequency,idf_values): #calculating tf-idf of query\n",
    "    keys = list(query_term_frequency.keys()) \n",
    "    query_tf_idf_matrix = {}\n",
    "    for i in range(0,len(query_term_frequency)):\n",
    "        query_tf_idf_matrix[keys[i]] = query_term_frequency[keys[i]] * idf_values[keys[i]]\n",
    "#         query_tf_idf_matrix[keys[i]] = query_term_frequency[keys[i]] * 1\n",
    "    return query_tf_idf_matrix\n",
    "\n",
    "def q_magnitude(query_tf_idf_matrix): #calculating magnitude of query\n",
    "    keys = list(query_tf_idf_matrix.keys())\n",
    "    total = 0\n",
    "    for i in range (0,len(query_tf_idf_matrix)):\n",
    "        temp = query_tf_idf_matrix[keys[i]]**2\n",
    "        total = total + temp\n",
    "    return (math.sqrt(total))\n",
    "\n",
    "\n",
    "def get_posting_list(new_query): ## get all documents in which query terms are present\n",
    "    temp = []\n",
    "    for i in range(0,len(new_query)):\n",
    "        temp.extend(list(term_frequency[new_query[i]][1].keys()))\n",
    "#         print(temp)\n",
    "    temp = list(dict.fromkeys(temp))\n",
    "    return temp \n",
    "\n",
    "\n",
    "def get_term_index_from_vocabulary(new_query,words_dictionary):\n",
    "    temp = []\n",
    "    for i in range(0,len(new_query)):\n",
    "        temp.append(words_dictionary.index(new_query[i]))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processing(query):\n",
    "    new_query = query.split()\n",
    "    stopword_list = create_stoplist()\n",
    "    new_query = [x for x in new_query if x not in stopword_list] # remove stop_Words from query\n",
    "    new_query = [lemmatizer.lemmatize(x) for x in new_query] # lemmatize the query\n",
    "    new_query = [x for x in new_query if x in words_dictionary] # remove words which are not in any document\n",
    "    if not new_query: #if after all removals if dicitionary is empty then a default ans is returned which is zero\n",
    "        return {0:0}\n",
    "    query_term_frequency = q_term_frequency(new_query) # creating term frequency of query matrix \n",
    "    query_tf_idf_matrix = create_q_tf_idf_matrix(query_term_frequency,idf_values) #  creating tf-idf matrix of query\n",
    "    query_magnitude = q_magnitude(query_tf_idf_matrix) # calculating magnitude of quer\n",
    "    documents = get_posting_list(new_query) # getting all documents which contain uery terms\n",
    "    term_index = get_term_index_from_vocabulary(new_query,words_dictionary) # getting positions of query term in dictionary of terms\n",
    "    cosine_scores = {} \n",
    "    for l in range(0,len(documents)): # calculating cosine scores\n",
    "        total = 0\n",
    "        temp = 0\n",
    "        for m in range(0,len(term_index)):\n",
    "            temp = tf_idf_matrix[documents[l]][term_index[m]] * query_tf_idf_matrix[new_query[m]]\n",
    "            total = total + temp\n",
    "        cosine_temp = total/(magnitudes[documents[l]] * query_magnitude)\n",
    "        cosine_scores[documents[l]] = cosine_temp\n",
    "#     {k: v for k, v in sorted(cosine_scores.items(), key=lambda item: item[1])}\n",
    "    return cosine_scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = input(\"Enter your Query: \")\n",
    "# result = []\n",
    "# result = query_processing(query)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Form implementation generated from reading ui file 'Vector Space Model.ui'\n",
    "#\n",
    "# Created by: PyQt5 UI code generator 5.15.2\n",
    "#\n",
    "# WARNING: Any manual changes made to this file will be lost when pyuic5 is\n",
    "# run again.  Do not edit this file unless you know what you are doing.\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Form implementation generated from reading ui file 'VectorSpaceModel.ui'\n",
    "#\n",
    "# Created by: PyQt5 UI code generator 5.15.2\n",
    "#\n",
    "# WARNING: Any manual changes made to this file will be lost when pyuic5 is\n",
    "# run again.  Do not edit this file unless you know what you are doing.\n",
    "\n",
    "\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "\n",
    "\n",
    "class Ui_Dialog(object):\n",
    "    def setupUi(self, Dialog):\n",
    "        Dialog.setObjectName(\"Dialog\")\n",
    "        Dialog.resize(586, 424)\n",
    "        self.listWidget = QtWidgets.QListWidget(Dialog)\n",
    "        self.listWidget.setGeometry(QtCore.QRect(20, 180, 256, 192))\n",
    "        self.listWidget.setObjectName(\"listWidget\")\n",
    "        self.listWidget_2 = QtWidgets.QListWidget(Dialog)\n",
    "        self.listWidget_2.setGeometry(QtCore.QRect(310, 180, 256, 192))\n",
    "        self.listWidget_2.setObjectName(\"listWidget_2\")\n",
    "        self.label_3 = QtWidgets.QLabel(Dialog)\n",
    "        self.label_3.setGeometry(QtCore.QRect(20, 130, 231, 31))\n",
    "        font = QtGui.QFont()\n",
    "        font.setPointSize(16)\n",
    "        self.label_3.setFont(font)\n",
    "        self.label_3.setObjectName(\"label_3\")\n",
    "        self.label_4 = QtWidgets.QLabel(Dialog)\n",
    "        self.label_4.setGeometry(QtCore.QRect(310, 140, 211, 21))\n",
    "        font = QtGui.QFont()\n",
    "        font.setPointSize(16)\n",
    "        self.label_4.setFont(font)\n",
    "        self.label_4.setObjectName(\"label_4\")\n",
    "        self.lineEdit = QtWidgets.QLineEdit(Dialog)\n",
    "        self.lineEdit.setGeometry(QtCore.QRect(100, 100, 311, 20))\n",
    "        self.lineEdit.setObjectName(\"lineEdit\")\n",
    "        self.label_2 = QtWidgets.QLabel(Dialog)\n",
    "        self.label_2.setGeometry(QtCore.QRect(20, 90, 81, 31))\n",
    "        font = QtGui.QFont()\n",
    "        font.setPointSize(16)\n",
    "        self.label_2.setFont(font)\n",
    "        self.label_2.setObjectName(\"label_2\")\n",
    "        self.pushButton = QtWidgets.QPushButton(Dialog)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(450, 100, 75, 23))\n",
    "        self.pushButton.setObjectName(\"pushButton\")\n",
    "        self.pushButton.clicked.connect(self.print1)\n",
    "        self.label = QtWidgets.QLabel(Dialog)\n",
    "        self.label.setGeometry(QtCore.QRect(50, 10, 531, 51))\n",
    "        font = QtGui.QFont()\n",
    "        font.setPointSize(36)\n",
    "        self.label.setFont(font)\n",
    "        self.label.setObjectName(\"label\")\n",
    "\n",
    "        self.retranslateUi(Dialog)\n",
    "        QtCore.QMetaObject.connectSlotsByName(Dialog)\n",
    "\n",
    "    def retranslateUi(self, Dialog):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        Dialog.setWindowTitle(_translate(\"Dialog\", \"Dialog\"))\n",
    "        self.label_3.setText(_translate(\"Dialog\", \"Ranked Results\"))\n",
    "        self.label_4.setText(_translate(\"Dialog\", \"Un-Ranked Results\"))\n",
    "        self.label_2.setText(_translate(\"Dialog\", \"Query\"))\n",
    "        self.pushButton.setText(_translate(\"Dialog\", \"Search\"))\n",
    "        self.label.setText(_translate(\"Dialog\", \"Vector Space Model\"))\n",
    "\n",
    "        \n",
    "    def print1(self):\n",
    "        self.listWidget_2.clear()\n",
    "        self.listWidget.clear()\n",
    "        self.result = query_processing(self.lineEdit.text())\n",
    "#         print(self.result)\n",
    "        self.keys = list(self.result.keys())\n",
    "        self.keys = [int(i) for i in self.keys]\n",
    "        self.keys.sort()\n",
    "    \n",
    "        if(self.keys[0] == 0):\n",
    "            self.listWidget_2.addItem(\"no Document Found\")\n",
    "            \n",
    "        else:    \n",
    "            for i in range (0,len(self.result)):\n",
    "                if self.result[str(self.keys[i])] >= 0.005:\n",
    "                    self.listWidget_2.addItem(\"Document \"+str(self.keys[i]))\n",
    "        \n",
    "        self.sorted_result = dict(sorted(self.result.items(), key=operator.itemgetter(1),reverse=True))\n",
    "        self.sorted_keys = list(self.sorted_result.keys())\n",
    "        \n",
    "        if(self.sorted_keys[0] == 0):\n",
    "            self.listWidget.addItem(\"no Document Found\")\n",
    "            \n",
    "        else:    \n",
    "            for i in range (0,len(self.sorted_result)):\n",
    "                if self.result[self.sorted_keys[i]] >= 0.005:\n",
    "                    self.listWidget.addItem(\"Document \"+str(self.sorted_keys[i]))\n",
    "                \n",
    "                \n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    Dialog = QtWidgets.QDialog()\n",
    "    ui = Ui_Dialog()\n",
    "    ui.setupUi(Dialog)\n",
    "    Dialog.show()\n",
    "    \n",
    "\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
